{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c771da7",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c2d4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c87e616",
   "metadata": {},
   "source": [
    "# clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5c92095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27610, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>time of day</th>\n",
       "      <th>location</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>...</th>\n",
       "      <th>user_mentions_indices_0</th>\n",
       "      <th>user_mentions_indices_1</th>\n",
       "      <th>user_mentions_name</th>\n",
       "      <th>user_mentions_screen_name</th>\n",
       "      <th>reply_to_user_results</th>\n",
       "      <th>quoted_tweet_results</th>\n",
       "      <th>quoted_tweet</th>\n",
       "      <th>retweeted_tweet</th>\n",
       "      <th>isConversationControlled</th>\n",
       "      <th>searchTermIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-02 00:00:46+00:00</td>\n",
       "      <td>1477429624208564226</td>\n",
       "      <td>https://x.com/KlausRieneck/status/147742962420...</td>\n",
       "      <td>The decision to phase outÂ nuclear powerÂ and sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'rest_id': '891466309619380224', 'result': {'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-02 00:00:50+00:00</td>\n",
       "      <td>1477429640675446785</td>\n",
       "      <td>https://x.com/EINRenewables/status/14774296406...</td>\n",
       "      <td>EU Moves to Label Nuclear, Natural Gas Energy ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   createdAt                   id  \\\n",
       "0  2022-01-02 00:00:46+00:00  1477429624208564226   \n",
       "1  2022-01-02 00:00:50+00:00  1477429640675446785   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://x.com/KlausRieneck/status/147742962420...   \n",
       "1  https://x.com/EINRenewables/status/14774296406...   \n",
       "\n",
       "                                                text  source        date  \\\n",
       "0  The decision to phase outÂ nuclear powerÂ and sh...     NaN  2022-01-02   \n",
       "1  EU Moves to Label Nuclear, Natural Gas Energy ...     NaN  2022-01-02   \n",
       "\n",
       "   time of day  location  retweetCount  replyCount  ...  \\\n",
       "0          0.0       NaN           0.0         0.0  ...   \n",
       "1          0.0       NaN           0.0         0.0  ...   \n",
       "\n",
       "   user_mentions_indices_0  user_mentions_indices_1  user_mentions_name  \\\n",
       "0                      NaN                      NaN                 NaN   \n",
       "1                      NaN                      NaN                 NaN   \n",
       "\n",
       "   user_mentions_screen_name  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "\n",
       "                               reply_to_user_results  quoted_tweet_results  \\\n",
       "0  {'rest_id': '891466309619380224', 'result': {'...                   NaN   \n",
       "1                                                NaN                   NaN   \n",
       "\n",
       "   quoted_tweet  retweeted_tweet isConversationControlled searchTermIndex  \n",
       "0           NaN              NaN                    False             0.0  \n",
       "1           NaN              NaN                    False             0.0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(\"../../data/csv/twitter_scraped_df.csv\", nrows=100)\n",
    "df = pd.read_csv(\"../../data/csv/twitter_scraped_df.csv\")\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04301a28",
   "metadata": {},
   "source": [
    "## ensure **createdAt** in **dtype** format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c73a1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns, UTC]\n",
      "0   2022-02-01 00:00:46+00:00\n",
      "1   2022-02-01 00:00:50+00:00\n",
      "Name: createdAt, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "df['createdAt'] = pd.to_datetime(df['createdAt'], dayfirst=True, errors='coerce')\n",
    "print(df['createdAt'].dtype)\n",
    "print(df['createdAt'][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc3253e",
   "metadata": {},
   "source": [
    "## extract author from url and insert as new column after 'id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc572e78",
   "metadata": {
    "vscode": {
     "languageId": "coffeescript"
    }
   },
   "outputs": [],
   "source": [
    "# extract author from url using regex\n",
    "# https://x.com/EINRenewables/status/14774296406\n",
    "# https://x.com/KlausRieneck/status/147742962420\n",
    "df['author'] = df['url'].str.extract(r'x\\.com/([^/]+)/status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c72610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move 'author' column after 'id'\n",
    "cols = list(df.columns)\n",
    "if 'author' in cols:\n",
    "    author_idx = cols.index('id') + 1\n",
    "    cols.insert(author_idx, cols.pop(cols.index('author')))\n",
    "    df = df[cols]\n",
    "# author_idx = cols.index('id') + 1\n",
    "# cols.insert(author_idx, cols.pop(cols.index('author')))\n",
    "# df = df[cols]\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eec42f",
   "metadata": {},
   "source": [
    "## drop columns if only contain 1 unique value or if all values are NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb0b52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>createdAt</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>time of day</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>user_mentions_id_str</th>\n",
       "      <th>user_mentions_indices_0</th>\n",
       "      <th>user_mentions_indices_1</th>\n",
       "      <th>user_mentions_name</th>\n",
       "      <th>user_mentions_screen_name</th>\n",
       "      <th>reply_to_user_results</th>\n",
       "      <th>quoted_tweet_results</th>\n",
       "      <th>quoted_tweet</th>\n",
       "      <th>isConversationControlled</th>\n",
       "      <th>searchTermIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-01 00:00:46+00:00</td>\n",
       "      <td>1477429624208564226</td>\n",
       "      <td>https://x.com/KlausRieneck/status/147742962420...</td>\n",
       "      <td>The decision to phase outÂ nuclear powerÂ and sh...</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'rest_id': '891466309619380224', 'result': {'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-01 00:00:50+00:00</td>\n",
       "      <td>1477429640675446785</td>\n",
       "      <td>https://x.com/EINRenewables/status/14774296406...</td>\n",
       "      <td>EU Moves to Label Nuclear, Natural Gas Energy ...</td>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  createdAt                   id  \\\n",
       "0 2022-02-01 00:00:46+00:00  1477429624208564226   \n",
       "1 2022-02-01 00:00:50+00:00  1477429640675446785   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://x.com/KlausRieneck/status/147742962420...   \n",
       "1  https://x.com/EINRenewables/status/14774296406...   \n",
       "\n",
       "                                                text        date  time of day  \\\n",
       "0  The decision to phase outÂ nuclear powerÂ and sh...  2022-01-02          0.0   \n",
       "1  EU Moves to Label Nuclear, Natural Gas Energy ...  2022-01-02          0.0   \n",
       "\n",
       "   retweetCount  replyCount  likeCount  quoteCount  ...  user_mentions_id_str  \\\n",
       "0           0.0         0.0        0.0         0.0  ...                   NaN   \n",
       "1           0.0         0.0        0.0         0.0  ...                   NaN   \n",
       "\n",
       "   user_mentions_indices_0 user_mentions_indices_1  user_mentions_name  \\\n",
       "0                      NaN                     NaN                 NaN   \n",
       "1                      NaN                     NaN                 NaN   \n",
       "\n",
       "   user_mentions_screen_name  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "\n",
       "                               reply_to_user_results quoted_tweet_results  \\\n",
       "0  {'rest_id': '891466309619380224', 'result': {'...                  NaN   \n",
       "1                                                NaN                  NaN   \n",
       "\n",
       "  quoted_tweet isConversationControlled  searchTermIndex  \n",
       "0          NaN                    False              0.0  \n",
       "1          NaN                    False              0.0  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = df.columns\n",
    "for col in columns:\n",
    "    if df[col].nunique(dropna=False) == 1 or df[col].isna().all():\n",
    "        df = df.drop(columns=[col])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437be551",
   "metadata": {},
   "source": [
    "## get unique tweet authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cd07f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'author'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SolarSoundBytes/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m unique_authors_nonan \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauthor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_authors_nonan[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SolarSoundBytes/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/SolarSoundBytes/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'author'"
     ]
    }
   ],
   "source": [
    "unique_authors = df['author'].dropna().unique()\n",
    "print(unique_authors[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f28f555",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2af1ed",
   "metadata": {},
   "source": [
    "## focus on tweet content, ignore twitter metrics columns for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0940ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['createdAt', 'id', 'author', 'url', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c9216",
   "metadata": {},
   "source": [
    "## check for missing values --> no need to delete or impute ðŸ˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0fdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb74258",
   "metadata": {},
   "source": [
    "## clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e41e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e43ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    '''\n",
    "    # remove whitespace\n",
    "    # lowercase\n",
    "    # remove hyperlinks\n",
    "    # punctuation and symbols like #\"*!&%\n",
    "    '''\n",
    "    # remove whitespace\n",
    "    text = text.strip(' ')\n",
    "\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # use regex to remove hyperlinks starting with http\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # remove punctuation and symbols like #\"*!&%\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # sentiment analysis --> keep stopwords\n",
    "    # to identify difference between 'not happy' and the separate words 'not', 'happy'\n",
    "\n",
    "    # lemmatize to group words by their meaning instead of their exact form\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    lemmatized_string = ' '.join(lemmatized_words)  # join back to string\n",
    "\n",
    "    return lemmatized_string\n",
    "\n",
    "df['text_clean'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df['text'][0:2])\n",
    "print(df['text_clean'][0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ad824",
   "metadata": {},
   "source": [
    "# Change the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36832a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean = df_clean.rename(columns={\n",
    "#     'date' : 'Date Published',\n",
    "#     'Clean Content' : 'Clean Article Text',\n",
    "#     'domain' : 'Author',\n",
    "#     'url' : 'URL'\n",
    "#     })\n",
    "# df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d55c6",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Testing\n",
    "Let's try different models, starting with the basic from \"Your first Transformers Challenge\" -- **\"twitter-roberta-base-sentiment-latest\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers torch\n",
    "%pip install datasets\n",
    "\n",
    "# %pip install transformers[torch]\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb34fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset, ClassLabel\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e361e",
   "metadata": {},
   "source": [
    "Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803be1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "df_sample = df['text', 'text_clean'].sample(n=100, random_state=42).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328d212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "sentiment_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4d6ffe",
   "metadata": {},
   "source": [
    "divide text into ***chunks*** of a **N** of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9741f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks(text, max_sentences=5):\n",
    "    \"Devide a text in chunks of N sentences\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    return [' '.join(sentences[i:i+max_sentences]) for i in range(0, len(sentences), max_sentences)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5da5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_sentiment_chunked(text):\n",
    "    \"Analyse sentiment of chunks and labels 'mixed' if there is a meaningful draw\"\n",
    "    try:\n",
    "        chunks = split_into_chunks(text[:500])\n",
    "        results = [sentiment_pipeline(chunk, truncation=True)[0] for chunk in chunks] # Truncar textos muy largos en chunk por chunk\n",
    "\n",
    "        labels = [r['label'] for r in results]\n",
    "        scores = [r['score'] for r in results]\n",
    "\n",
    "        counter = Counter(labels)\n",
    "        majority_label, count = counter.most_common(1)[0]\n",
    "        avg_score = sum([s for l, s in zip(labels, scores) if l == majority_label]) / count\n",
    "\n",
    "        if avg_score < 0.4:\n",
    "            majority_label = 'NEUTRAL'\n",
    "\n",
    "        return pd.Series([majority_label, avg_score])\n",
    "    except Exception as e:\n",
    "        print(f\"Error en analyze_sentiment_chunked: {e}\")\n",
    "        return pd.Series([None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sample['text_clean'].apply(analyze_sentiment_chunked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40a8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sample[df_sample['sentiment'] == 'negative'].sample()['Clean Article Text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e034f4",
   "metadata": {},
   "source": [
    "# Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce45363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/enrique/code/EFRdev/08-Final-Project/SolarSoundBytes/raw_data/ForTraining_news_sentiment_analysis.csv')\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e99983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Published At'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c7544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['Published At'] = pd.to_datetime(df_train['Published At'], dayfirst=True, errors='coerce')\n",
    "df_train['Published At'] = df_train['Published At'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb047d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = df_train.columns.str.strip()\n",
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7acaa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c9ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['negative', 'neutral', 'positive']\n",
    "label_to_id = {l: i for i, l in enumerate(label_list)}\n",
    "df_train['label_id'] = df_train['Sentiment'].map(label_to_id)\n",
    "\n",
    "#Turning Dataset into HuggingFace object\n",
    "dataset = Dataset.from_pandas(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d9eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_list))\n",
    "\n",
    "#Tokenizing\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text[\"Description\"], truncation=True, padding='max_length', max_length=128)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "#Split dataset train and val\n",
    "split = tokenized_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split['train']\n",
    "val_dataset = split['test']\n",
    "\n",
    "#Evaluation Metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}\n",
    "\n",
    "#Training set up & Training\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args = training_args, train_dataset=train_dataset, eval_dataset = val_dataset, compute_metrics=compute_metrics)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c5d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc488f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291901b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd2f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf188cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./modelo_finetuned\")\n",
    "tokenizer.save_pretrained(\"./modelo_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aeb7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SolarSoundBytes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
